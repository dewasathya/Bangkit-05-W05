{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bangkit 05-W05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuqUAPkMt6hp",
        "colab_type": "text"
      },
      "source": [
        "Import libraries and check TF version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4DVtkd9CxEa",
        "colab_type": "code",
        "outputId": "607b16ed-bda2-48ee-d061-9f5c066d3b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# TensorFlow Library\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Feature Engineering Library\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Helper Library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk9xIOT7t1W9",
        "colab_type": "text"
      },
      "source": [
        "Get dataset from Github repo and load it to Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7lzcAZ1tnVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DS_TRAINING_URL = 'https://raw.githubusercontent.com/dewasathya/Bangkit-05-W05/master/titanic-extended/train.csv'\n",
        "DS_TEST_URL = 'https://raw.githubusercontent.com/dewasathya/Bangkit-05-W05/master/titanic-extended/test.csv'\n",
        "\n",
        "train_data = pd.read_csv(DS_TRAINING_URL)\n",
        "test_data = pd.read_csv(DS_TEST_URL)\n",
        "\n",
        "#train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtTk5eG6GBqT",
        "colab_type": "text"
      },
      "source": [
        "Filling empty cells with values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGIvJw57xZwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Engineering\n",
        "def nan_padding(data, columns):\n",
        "  for column in columns:\n",
        "    imputer = SimpleImputer()\n",
        "    data[column] = imputer.fit_transform(data[column].values.reshape(-1, 1))\n",
        "  return data\n",
        "\n",
        "nan_columns = [\"Age\", \"SibSp\", \"Parch\"]\n",
        "train_data = nan_padding(train_data, nan_columns)\n",
        "test_data = nan_padding(test_data, nan_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCl4simtHNHW",
        "colab_type": "text"
      },
      "source": [
        "Saving Passenger ID for final result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpSDzs1rzWEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save PassengerId for evaluation\n",
        "test_passenger_id = test_data[\"PassengerId\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv0yNEzMHWoe",
        "colab_type": "text"
      },
      "source": [
        "Dropping unnecessary columns from training and test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvxWJ5O8zqXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop not needed columns\n",
        "def drop_not_concerned(data, columns):\n",
        "  return data.drop(columns, axis=1)\n",
        "\n",
        "not_concerned_columns = [\n",
        "                         \"PassengerId\", \"Name\", \"Ticket\", \"Fare\",\n",
        "                         \"Cabin\", \"Embarked\", \"WikiId\", \"Name_wiki\",\n",
        "                         \"Age_wiki\", \"Hometown\", \"Boarded\", \"Destination\",\n",
        "                         \"Lifeboat\", \"Body\", \"Class\"\n",
        "]\n",
        "train_data = drop_not_concerned(train_data, not_concerned_columns)\n",
        "test_data = drop_not_concerned(test_data, not_concerned_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-npQKxU1KV-",
        "colab_type": "code",
        "outputId": "02c19111-8f5c-45b3-f7d6-dd97506809e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
              "0       0.0       3    male  22.0    1.0    0.0\n",
              "1       1.0       1  female  38.0    1.0    0.0\n",
              "2       1.0       3  female  26.0    0.0    0.0\n",
              "3       1.0       1  female  35.0    1.0    0.0\n",
              "4       0.0       3    male  35.0    0.0    0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwtultpioeRj",
        "colab_type": "code",
        "outputId": "bdaa5de8-5500-4a2b-d30a-e53c741dc903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pclass     Sex   Age  SibSp  Parch\n",
              "0       3    male  34.5    0.0    0.0\n",
              "1       3  female  47.0    1.0    0.0\n",
              "2       2    male  62.0    0.0    0.0\n",
              "3       3    male  27.0    0.0    0.0\n",
              "4       3  female  22.0    1.0    1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUWcatMGHsCw",
        "colab_type": "text"
      },
      "source": [
        "Separate Pclass into 3 (Pclass_1, Pclass_2, Pclass_3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJELGkHToqlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dummy_data(data, columns):\n",
        "  for column in columns:\n",
        "    data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n",
        "    data = data.drop(column, axis=1)\n",
        "  return data\n",
        "\n",
        "dummy_columns = [\"Pclass\"]\n",
        "train_data=dummy_data(train_data, dummy_columns)\n",
        "test_data=dummy_data(test_data, dummy_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF5wiOpQpL1Z",
        "colab_type": "code",
        "outputId": "03e9e14f-8e48-433a-badf-dfeb89389079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Sex   Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
              "0    male  34.5    0.0    0.0         0         0         1\n",
              "1  female  47.0    1.0    0.0         0         0         1\n",
              "2    male  62.0    0.0    0.0         0         1         0\n",
              "3    male  27.0    0.0    0.0         0         0         1\n",
              "4  female  22.0    1.0    1.0         0         0         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33wjHGB0LxBH",
        "colab_type": "text"
      },
      "source": [
        "Transform sex to number. Male = 0, Female = 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fCRwr6gjQDK",
        "colab_type": "code",
        "outputId": "b3fcab93-148a-4954-8aa6-df12129fb89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def sex_to_int(data):\n",
        "  le = LabelEncoder()\n",
        "  le.fit([\"male\",\"female\"])\n",
        "  data[\"Sex\"]=le.transform(data[\"Sex\"]) \n",
        "  return data\n",
        "\n",
        "train_data = sex_to_int(train_data)\n",
        "test_data = sex_to_int(test_data)\n",
        "train_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Sex   Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
              "0       0.0    1  22.0    1.0    0.0         0         0         1\n",
              "1       1.0    0  38.0    1.0    0.0         1         0         0\n",
              "2       1.0    0  26.0    0.0    0.0         0         0         1\n",
              "3       1.0    0  35.0    1.0    0.0         1         0         0\n",
              "4       0.0    1  35.0    0.0    0.0         0         0         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG7rIerRMNay",
        "colab_type": "text"
      },
      "source": [
        "Normalize passenger's age."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXhXK3Rsjbq2",
        "colab_type": "code",
        "outputId": "f0715446-1848-4230-f47f-25988f22d252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def normalize_age(data):\n",
        "  scaler = MinMaxScaler()\n",
        "  data[\"Age\"] = scaler.fit_transform(data[\"Age\"].values.reshape(-1,1))\n",
        "  return data\n",
        "  \n",
        "train_data = normalize_age(train_data)\n",
        "test_data = normalize_age(test_data)\n",
        "train_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Sex       Age  SibSp  Parch  Pclass_1  Pclass_2  Pclass_3\n",
              "0       0.0    1  0.271174    1.0    0.0         0         0         1\n",
              "1       1.0    0  0.472229    1.0    0.0         1         0         0\n",
              "2       1.0    0  0.321438    0.0    0.0         0         0         1\n",
              "3       1.0    0  0.434531    1.0    0.0         1         0         0\n",
              "4       0.0    1  0.434531    0.0    0.0         0         0         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUODrT3RjoCx",
        "colab_type": "code",
        "outputId": "258ae2d6-4c34-43c5-e6f1-244a05f5607f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_valid_test_data(data, fraction=(1 - 0.8)):\n",
        "  data_y = data[\"Survived\"]\n",
        "  lb = LabelBinarizer()\n",
        "  data_y = lb.fit_transform(data_y)\n",
        "\n",
        "  data_x = data.drop([\"Survived\"], axis=1)\n",
        "\n",
        "  train_x, valid_x, train_y, valid_y = train_test_split(data_x, data_y, test_size=fraction)\n",
        "\n",
        "  return train_x.values, train_y, valid_x, valid_y\n",
        "\n",
        "train_x, train_y, valid_x, valid_y = split_valid_test_data(train_data)\n",
        "print(\"train_x:{}\".format(train_x.shape))\n",
        "print(\"train_y:{}\".format(train_y.shape))\n",
        "print(\"train_y content:{}\".format(train_y[:3]))\n",
        "\n",
        "print(\"valid_x:{}\".format(valid_x.shape))\n",
        "print(\"valid_y:{}\".format(valid_y.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x:(712, 7)\n",
            "train_y:(712, 1)\n",
            "train_y content:[[0]\n",
            " [0]\n",
            " [1]]\n",
            "valid_x:(179, 7)\n",
            "valid_y:(179, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z0Uj5S0Mhgn",
        "colab_type": "text"
      },
      "source": [
        "Build the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-8nVC7vkH-b",
        "colab_type": "code",
        "outputId": "6439e787-49d1-428a-fad9-4b336552914c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# Build Neural Network\n",
        "from collections import namedtuple\n",
        "\n",
        "def build_neural_network(hidden_units=10):\n",
        "  tf.reset_default_graph()\n",
        "  inputs = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n",
        "  labels = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "  learning_rate = tf.placeholder(tf.float32)\n",
        "  is_training=tf.Variable(True,dtype=tf.bool)\n",
        "\n",
        "  initializer = tf.contrib.layers.xavier_initializer()\n",
        "  fc = tf.layers.dense(inputs, hidden_units, activation=None,kernel_initializer=initializer)\n",
        "  fc=tf.layers.batch_normalization(fc, training=is_training)\n",
        "  fc=tf.nn.relu(fc)\n",
        "\n",
        "  logits = tf.layers.dense(fc, 1, activation=None)\n",
        "  cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
        "  cost = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "  with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "      optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "  predicted = tf.nn.sigmoid(logits)\n",
        "  correct_pred = tf.equal(tf.round(predicted), labels)\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  # Export the nodes \n",
        "  export_nodes = ['inputs', 'labels', 'learning_rate','is_training', 'logits',\n",
        "                  'cost', 'optimizer', 'predicted', 'accuracy']\n",
        "  Graph = namedtuple('Graph', export_nodes)\n",
        "  local_dict = locals()\n",
        "  graph = Graph(*[local_dict[each] for each in export_nodes])\n",
        "\n",
        "  return graph\n",
        "\n",
        "model = build_neural_network()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-13-f303ceef9516>:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-13-f303ceef9516>:12: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvQib1vEFFw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(data_x,data_y,batch_size=32):\n",
        "  batch_n=len(data_x)//batch_size\n",
        "  for i in range(batch_n):\n",
        "    batch_x=data_x[i*batch_size:(i+1)*batch_size]\n",
        "    batch_y=data_y[i*batch_size:(i+1)*batch_size]\n",
        "    \n",
        "    yield batch_x,batch_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSop85Y7FLWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28ab996e-d440-4cae-b49f-30b50f9fd947"
      },
      "source": [
        "epochs = 200\n",
        "train_collect = 50\n",
        "train_print=train_collect*2\n",
        "\n",
        "learning_rate_value = 0.001\n",
        "batch_size=16\n",
        "\n",
        "x_collect = []\n",
        "train_loss_collect = []\n",
        "train_acc_collect = []\n",
        "valid_loss_collect = []\n",
        "valid_acc_collect = []\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  iteration=0\n",
        "  for e in range(epochs):\n",
        "    for batch_x,batch_y in get_batch(train_x,train_y,batch_size):\n",
        "      iteration+=1\n",
        "      feed = {model.inputs: train_x, \n",
        "              model.labels: train_y, \n",
        "              model.learning_rate: learning_rate_value, \n",
        "              model.is_training:True}\n",
        "\n",
        "      train_loss, _, train_acc = sess.run([model.cost, model.optimizer, model.accuracy], feed_dict=feed)\n",
        "      \n",
        "      if iteration % train_collect == 0:\n",
        "        ##\n",
        "        x_collect.append(e)\n",
        "        train_loss_collect.append(train_loss)\n",
        "        train_acc_collect.append(train_acc)\n",
        "\n",
        "        if iteration % train_print==0:\n",
        "          ##\n",
        "          print(\"Epoch: {}/{}\".format(e + 1, epochs),\n",
        "          \"Train Loss: {:.4f}\".format(train_loss),\n",
        "          \"Train Acc: {:.4f}\".format(train_acc))\n",
        "                \n",
        "        feed = {model.inputs: valid_x,\n",
        "                model.labels: valid_y,\n",
        "                model.is_training:False}\n",
        "        val_loss, val_acc = sess.run([model.cost, model.accuracy], feed_dict=feed)\n",
        "        valid_loss_collect.append(val_loss)\n",
        "        valid_acc_collect.append(val_acc)\n",
        "        \n",
        "        if iteration % train_print==0:\n",
        "          ##\n",
        "          print(\"Epoch: {}/{}\".format(e + 1, epochs), \n",
        "                \"Validation Loss: {:.4f}\".format(val_loss), \n",
        "                \"Validation Acc: {:.4f}\".format(val_acc))\n",
        "  \n",
        "  saver.save(sess, \"./titanic.ckpt\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3/200 Train Loss: 0.5115 Train Acc: 0.7837\n",
            "Epoch: 3/200 Validation Loss: 0.5900 Validation Acc: 0.7263\n",
            "Epoch: 5/200 Train Loss: 0.4454 Train Acc: 0.8174\n",
            "Epoch: 5/200 Validation Loss: 0.5072 Validation Acc: 0.7709\n",
            "Epoch: 7/200 Train Loss: 0.4216 Train Acc: 0.8188\n",
            "Epoch: 7/200 Validation Loss: 0.4598 Validation Acc: 0.7709\n",
            "Epoch: 10/200 Train Loss: 0.4130 Train Acc: 0.8216\n",
            "Epoch: 10/200 Validation Loss: 0.4426 Validation Acc: 0.7989\n",
            "Epoch: 12/200 Train Loss: 0.4095 Train Acc: 0.8244\n",
            "Epoch: 12/200 Validation Loss: 0.4375 Validation Acc: 0.7877\n",
            "Epoch: 14/200 Train Loss: 0.4074 Train Acc: 0.8216\n",
            "Epoch: 14/200 Validation Loss: 0.4368 Validation Acc: 0.7877\n",
            "Epoch: 16/200 Train Loss: 0.4059 Train Acc: 0.8216\n",
            "Epoch: 16/200 Validation Loss: 0.4367 Validation Acc: 0.7821\n",
            "Epoch: 19/200 Train Loss: 0.4050 Train Acc: 0.8258\n",
            "Epoch: 19/200 Validation Loss: 0.4350 Validation Acc: 0.7989\n",
            "Epoch: 21/200 Train Loss: 0.4041 Train Acc: 0.8244\n",
            "Epoch: 21/200 Validation Loss: 0.4350 Validation Acc: 0.7989\n",
            "Epoch: 23/200 Train Loss: 0.4031 Train Acc: 0.8272\n",
            "Epoch: 23/200 Validation Loss: 0.4347 Validation Acc: 0.7989\n",
            "Epoch: 25/200 Train Loss: 0.4020 Train Acc: 0.8258\n",
            "Epoch: 25/200 Validation Loss: 0.4347 Validation Acc: 0.7989\n",
            "Epoch: 28/200 Train Loss: 0.4010 Train Acc: 0.8244\n",
            "Epoch: 28/200 Validation Loss: 0.4350 Validation Acc: 0.7989\n",
            "Epoch: 30/200 Train Loss: 0.4004 Train Acc: 0.8287\n",
            "Epoch: 30/200 Validation Loss: 0.4343 Validation Acc: 0.7989\n",
            "Epoch: 32/200 Train Loss: 0.3996 Train Acc: 0.8272\n",
            "Epoch: 32/200 Validation Loss: 0.4321 Validation Acc: 0.7989\n",
            "Epoch: 35/200 Train Loss: 0.3988 Train Acc: 0.8287\n",
            "Epoch: 35/200 Validation Loss: 0.4335 Validation Acc: 0.7989\n",
            "Epoch: 37/200 Train Loss: 0.3981 Train Acc: 0.8315\n",
            "Epoch: 37/200 Validation Loss: 0.4325 Validation Acc: 0.7989\n",
            "Epoch: 39/200 Train Loss: 0.3976 Train Acc: 0.8329\n",
            "Epoch: 39/200 Validation Loss: 0.4318 Validation Acc: 0.7989\n",
            "Epoch: 41/200 Train Loss: 0.3970 Train Acc: 0.8343\n",
            "Epoch: 41/200 Validation Loss: 0.4323 Validation Acc: 0.7989\n",
            "Epoch: 44/200 Train Loss: 0.3962 Train Acc: 0.8329\n",
            "Epoch: 44/200 Validation Loss: 0.4310 Validation Acc: 0.7933\n",
            "Epoch: 46/200 Train Loss: 0.3959 Train Acc: 0.8343\n",
            "Epoch: 46/200 Validation Loss: 0.4286 Validation Acc: 0.7933\n",
            "Epoch: 48/200 Train Loss: 0.3956 Train Acc: 0.8343\n",
            "Epoch: 48/200 Validation Loss: 0.4275 Validation Acc: 0.7933\n",
            "Epoch: 50/200 Train Loss: 0.3952 Train Acc: 0.8343\n",
            "Epoch: 50/200 Validation Loss: 0.4268 Validation Acc: 0.7933\n",
            "Epoch: 53/200 Train Loss: 0.3949 Train Acc: 0.8357\n",
            "Epoch: 53/200 Validation Loss: 0.4267 Validation Acc: 0.7933\n",
            "Epoch: 55/200 Train Loss: 0.3945 Train Acc: 0.8357\n",
            "Epoch: 55/200 Validation Loss: 0.4251 Validation Acc: 0.7989\n",
            "Epoch: 57/200 Train Loss: 0.3941 Train Acc: 0.8357\n",
            "Epoch: 57/200 Validation Loss: 0.4244 Validation Acc: 0.7989\n",
            "Epoch: 60/200 Train Loss: 0.3936 Train Acc: 0.8343\n",
            "Epoch: 60/200 Validation Loss: 0.4249 Validation Acc: 0.8045\n",
            "Epoch: 62/200 Train Loss: 0.3931 Train Acc: 0.8343\n",
            "Epoch: 62/200 Validation Loss: 0.4233 Validation Acc: 0.8045\n",
            "Epoch: 64/200 Train Loss: 0.3921 Train Acc: 0.8357\n",
            "Epoch: 64/200 Validation Loss: 0.4214 Validation Acc: 0.8101\n",
            "Epoch: 66/200 Train Loss: 0.3903 Train Acc: 0.8357\n",
            "Epoch: 66/200 Validation Loss: 0.4167 Validation Acc: 0.7989\n",
            "Epoch: 69/200 Train Loss: 0.3893 Train Acc: 0.8357\n",
            "Epoch: 69/200 Validation Loss: 0.4155 Validation Acc: 0.8045\n",
            "Epoch: 71/200 Train Loss: 0.3878 Train Acc: 0.8357\n",
            "Epoch: 71/200 Validation Loss: 0.4158 Validation Acc: 0.8101\n",
            "Epoch: 73/200 Train Loss: 0.3867 Train Acc: 0.8343\n",
            "Epoch: 73/200 Validation Loss: 0.4170 Validation Acc: 0.8101\n",
            "Epoch: 75/200 Train Loss: 0.3861 Train Acc: 0.8343\n",
            "Epoch: 75/200 Validation Loss: 0.4201 Validation Acc: 0.8045\n",
            "Epoch: 78/200 Train Loss: 0.3857 Train Acc: 0.8343\n",
            "Epoch: 78/200 Validation Loss: 0.4213 Validation Acc: 0.8045\n",
            "Epoch: 80/200 Train Loss: 0.3853 Train Acc: 0.8371\n",
            "Epoch: 80/200 Validation Loss: 0.4222 Validation Acc: 0.8045\n",
            "Epoch: 82/200 Train Loss: 0.3848 Train Acc: 0.8385\n",
            "Epoch: 82/200 Validation Loss: 0.4216 Validation Acc: 0.7989\n",
            "Epoch: 85/200 Train Loss: 0.3845 Train Acc: 0.8371\n",
            "Epoch: 85/200 Validation Loss: 0.4259 Validation Acc: 0.7933\n",
            "Epoch: 87/200 Train Loss: 0.3843 Train Acc: 0.8371\n",
            "Epoch: 87/200 Validation Loss: 0.4252 Validation Acc: 0.7989\n",
            "Epoch: 89/200 Train Loss: 0.3841 Train Acc: 0.8385\n",
            "Epoch: 89/200 Validation Loss: 0.4231 Validation Acc: 0.7989\n",
            "Epoch: 91/200 Train Loss: 0.3838 Train Acc: 0.8399\n",
            "Epoch: 91/200 Validation Loss: 0.4285 Validation Acc: 0.7989\n",
            "Epoch: 94/200 Train Loss: 0.3830 Train Acc: 0.8371\n",
            "Epoch: 94/200 Validation Loss: 0.4274 Validation Acc: 0.7933\n",
            "Epoch: 96/200 Train Loss: 0.3823 Train Acc: 0.8371\n",
            "Epoch: 96/200 Validation Loss: 0.4233 Validation Acc: 0.7989\n",
            "Epoch: 98/200 Train Loss: 0.3818 Train Acc: 0.8385\n",
            "Epoch: 98/200 Validation Loss: 0.4260 Validation Acc: 0.7989\n",
            "Epoch: 100/200 Train Loss: 0.3814 Train Acc: 0.8385\n",
            "Epoch: 100/200 Validation Loss: 0.4279 Validation Acc: 0.7989\n",
            "Epoch: 103/200 Train Loss: 0.3811 Train Acc: 0.8385\n",
            "Epoch: 103/200 Validation Loss: 0.4280 Validation Acc: 0.7989\n",
            "Epoch: 105/200 Train Loss: 0.3808 Train Acc: 0.8399\n",
            "Epoch: 105/200 Validation Loss: 0.4305 Validation Acc: 0.7989\n",
            "Epoch: 107/200 Train Loss: 0.3806 Train Acc: 0.8399\n",
            "Epoch: 107/200 Validation Loss: 0.4287 Validation Acc: 0.8156\n",
            "Epoch: 110/200 Train Loss: 0.3805 Train Acc: 0.8413\n",
            "Epoch: 110/200 Validation Loss: 0.4299 Validation Acc: 0.8045\n",
            "Epoch: 112/200 Train Loss: 0.3804 Train Acc: 0.8399\n",
            "Epoch: 112/200 Validation Loss: 0.4288 Validation Acc: 0.7989\n",
            "Epoch: 114/200 Train Loss: 0.3803 Train Acc: 0.8385\n",
            "Epoch: 114/200 Validation Loss: 0.4326 Validation Acc: 0.7989\n",
            "Epoch: 116/200 Train Loss: 0.3802 Train Acc: 0.8357\n",
            "Epoch: 116/200 Validation Loss: 0.4333 Validation Acc: 0.7989\n",
            "Epoch: 119/200 Train Loss: 0.3802 Train Acc: 0.8357\n",
            "Epoch: 119/200 Validation Loss: 0.4365 Validation Acc: 0.7989\n",
            "Epoch: 121/200 Train Loss: 0.3801 Train Acc: 0.8357\n",
            "Epoch: 121/200 Validation Loss: 0.4320 Validation Acc: 0.8045\n",
            "Epoch: 123/200 Train Loss: 0.3801 Train Acc: 0.8357\n",
            "Epoch: 123/200 Validation Loss: 0.4300 Validation Acc: 0.8045\n",
            "Epoch: 125/200 Train Loss: 0.3798 Train Acc: 0.8371\n",
            "Epoch: 125/200 Validation Loss: 0.4293 Validation Acc: 0.8101\n",
            "Epoch: 128/200 Train Loss: 0.3796 Train Acc: 0.8371\n",
            "Epoch: 128/200 Validation Loss: 0.4262 Validation Acc: 0.8156\n",
            "Epoch: 130/200 Train Loss: 0.3792 Train Acc: 0.8371\n",
            "Epoch: 130/200 Validation Loss: 0.4338 Validation Acc: 0.8045\n",
            "Epoch: 132/200 Train Loss: 0.3788 Train Acc: 0.8343\n",
            "Epoch: 132/200 Validation Loss: 0.4360 Validation Acc: 0.7989\n",
            "Epoch: 135/200 Train Loss: 0.3781 Train Acc: 0.8371\n",
            "Epoch: 135/200 Validation Loss: 0.4393 Validation Acc: 0.7989\n",
            "Epoch: 137/200 Train Loss: 0.3779 Train Acc: 0.8385\n",
            "Epoch: 137/200 Validation Loss: 0.4323 Validation Acc: 0.8101\n",
            "Epoch: 139/200 Train Loss: 0.3777 Train Acc: 0.8385\n",
            "Epoch: 139/200 Validation Loss: 0.4310 Validation Acc: 0.8101\n",
            "Epoch: 141/200 Train Loss: 0.3775 Train Acc: 0.8385\n",
            "Epoch: 141/200 Validation Loss: 0.4274 Validation Acc: 0.8156\n",
            "Epoch: 144/200 Train Loss: 0.3774 Train Acc: 0.8385\n",
            "Epoch: 144/200 Validation Loss: 0.4288 Validation Acc: 0.8101\n",
            "Epoch: 146/200 Train Loss: 0.3773 Train Acc: 0.8385\n",
            "Epoch: 146/200 Validation Loss: 0.4330 Validation Acc: 0.8156\n",
            "Epoch: 148/200 Train Loss: 0.3772 Train Acc: 0.8385\n",
            "Epoch: 148/200 Validation Loss: 0.4368 Validation Acc: 0.8101\n",
            "Epoch: 150/200 Train Loss: 0.3772 Train Acc: 0.8385\n",
            "Epoch: 150/200 Validation Loss: 0.4331 Validation Acc: 0.8101\n",
            "Epoch: 153/200 Train Loss: 0.3771 Train Acc: 0.8371\n",
            "Epoch: 153/200 Validation Loss: 0.4292 Validation Acc: 0.8156\n",
            "Epoch: 155/200 Train Loss: 0.3771 Train Acc: 0.8371\n",
            "Epoch: 155/200 Validation Loss: 0.4277 Validation Acc: 0.8101\n",
            "Epoch: 157/200 Train Loss: 0.3770 Train Acc: 0.8385\n",
            "Epoch: 157/200 Validation Loss: 0.4248 Validation Acc: 0.8101\n",
            "Epoch: 160/200 Train Loss: 0.3769 Train Acc: 0.8371\n",
            "Epoch: 160/200 Validation Loss: 0.4273 Validation Acc: 0.8101\n",
            "Epoch: 162/200 Train Loss: 0.3769 Train Acc: 0.8371\n",
            "Epoch: 162/200 Validation Loss: 0.4271 Validation Acc: 0.8101\n",
            "Epoch: 164/200 Train Loss: 0.3769 Train Acc: 0.8385\n",
            "Epoch: 164/200 Validation Loss: 0.4276 Validation Acc: 0.8156\n",
            "Epoch: 166/200 Train Loss: 0.3769 Train Acc: 0.8343\n",
            "Epoch: 166/200 Validation Loss: 0.4288 Validation Acc: 0.8156\n",
            "Epoch: 169/200 Train Loss: 0.3769 Train Acc: 0.8343\n",
            "Epoch: 169/200 Validation Loss: 0.4391 Validation Acc: 0.7989\n",
            "Epoch: 171/200 Train Loss: 0.3768 Train Acc: 0.8343\n",
            "Epoch: 171/200 Validation Loss: 0.4338 Validation Acc: 0.8156\n",
            "Epoch: 173/200 Train Loss: 0.3768 Train Acc: 0.8357\n",
            "Epoch: 173/200 Validation Loss: 0.4330 Validation Acc: 0.8101\n",
            "Epoch: 175/200 Train Loss: 0.3768 Train Acc: 0.8357\n",
            "Epoch: 175/200 Validation Loss: 0.4363 Validation Acc: 0.8101\n",
            "Epoch: 178/200 Train Loss: 0.3767 Train Acc: 0.8343\n",
            "Epoch: 178/200 Validation Loss: 0.4324 Validation Acc: 0.8101\n",
            "Epoch: 180/200 Train Loss: 0.3766 Train Acc: 0.8385\n",
            "Epoch: 180/200 Validation Loss: 0.4326 Validation Acc: 0.8101\n",
            "Epoch: 182/200 Train Loss: 0.3764 Train Acc: 0.8357\n",
            "Epoch: 182/200 Validation Loss: 0.4331 Validation Acc: 0.8101\n",
            "Epoch: 185/200 Train Loss: 0.3763 Train Acc: 0.8385\n",
            "Epoch: 185/200 Validation Loss: 0.4302 Validation Acc: 0.8156\n",
            "Epoch: 187/200 Train Loss: 0.3761 Train Acc: 0.8385\n",
            "Epoch: 187/200 Validation Loss: 0.4295 Validation Acc: 0.8045\n",
            "Epoch: 189/200 Train Loss: 0.3759 Train Acc: 0.8413\n",
            "Epoch: 189/200 Validation Loss: 0.4264 Validation Acc: 0.7989\n",
            "Epoch: 191/200 Train Loss: 0.3758 Train Acc: 0.8413\n",
            "Epoch: 191/200 Validation Loss: 0.4287 Validation Acc: 0.7989\n",
            "Epoch: 194/200 Train Loss: 0.3756 Train Acc: 0.8399\n",
            "Epoch: 194/200 Validation Loss: 0.4301 Validation Acc: 0.7989\n",
            "Epoch: 196/200 Train Loss: 0.3746 Train Acc: 0.8413\n",
            "Epoch: 196/200 Validation Loss: 0.4344 Validation Acc: 0.7989\n",
            "Epoch: 198/200 Train Loss: 0.3742 Train Acc: 0.8413\n",
            "Epoch: 198/200 Validation Loss: 0.4247 Validation Acc: 0.7989\n",
            "Epoch: 200/200 Train Loss: 0.3741 Train Acc: 0.8427\n",
            "Epoch: 200/200 Validation Loss: 0.4264 Validation Acc: 0.7989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Dq-yDXFR1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ed6b1bef-0fde-48e9-b355-17e3f26f22dd"
      },
      "source": [
        "plt.plot(x_collect, train_loss_collect, \"r--\")\n",
        "plt.plot(x_collect, valid_loss_collect, \"g^\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSvQiIjH3/wEA8qqWr3/w4wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S27A0TImFdXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "1be13e46-2810-42c1-a8f7-31918f530718"
      },
      "source": [
        "plt.plot(x_collect, train_acc_collect, \"r--\")\n",
        "plt.plot(x_collect, valid_acc_collect, \"g^\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD6CAYAAACoCZCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7wVdb3/8dcHUCHNC4FlIoIdTFGL\njlvDrDx61MhKtEwhS00Nzezi6YZdTfSk9eiYnENeCgHNBFNLfqmpmddEYxMbuXhD8AJulJsComzY\n+/P74zvLPXvtdZm19lp7rb3n/Xw81oO1vzPznc/MLOY73+985zvm7oiISPr0qXUAIiJSGyoARERS\nSgWAiEhKqQAQEUkpFQAiIimlAkBEJKUSFQBmNsbMnjazpWY2Mcf0oWZ2v5nNN7MnzOy4KH2Ymb1p\nZk3R5+rYMgeb2cIoz8lmZpXbLBERKcaKPQdgZn2BZ4BjgBXAXGC8uy+JzXMtMN/drzKzkcCd7j7M\nzIYBf3H3A3Pk+0/gG8DjwJ3AZHe/q1AsgwYN8mHDhiXfOhERYd68eWvcfXB2er8Eyx4KLHX3ZQBm\nNhMYCyyJzePAztH3XYCXC2VoZnsAO7v7Y9Hf1wMnAAULgGHDhtHY2JggZBERyTCzF3KlJ2kC2hN4\nKfb3iigt7iLgi2a2gnA1//XYtOFR09CDZvaxWJ4riuQpIiJVVKmbwOOB6e4+BDgOuMHM+gDNwFB3\n/xDwX8AfzGznAvl0YmYTzKzRzBpXr15doXBFRCRJAbAS2Cv295AoLe4s4GYAd58D9AcGufsWd18b\npc8DngP2jZYfUiRPouWudfcGd28YPLhTE5aIiJQpSQEwFxhhZsPNbHtgHDA7a54Xgf8EMLP9CQXA\najMbHN1Exsz2AUYAy9y9GdhgZqOj3j+nAbdXZItERCSRojeB3X2bmZ0P3A30Ba5z98VmdjHQ6O6z\ngW8DvzWzCwg3hM9wdzezjwMXm9lWoA04193XRVmfB0wHBhBu/ha8ASwiIpVVtBtoPWloaHD1AhIR\nKY2ZzXP3hux0PQksIpJSKgBEROrdypx9ZLpMBYBId3KHrVvDZ9u2Wkcj3aGtrf175tjnO/7btrVP\nnz27fdnm5qqEpgJApLusWwcf+xhsv334nH12SHeH++6rbWxSHY89Bp//fPvfw4a1H//+/eHSS8Px\nb2uDb32rfdr228PYsXDDDWG5hk7N9xWRZCgIkd7NHW68Mfzn/OhH4dVX4dln4fDDu5bv+vWw665g\nBgsXwmc/Cy++CBdeCDvuCB/4QJjvhhvg9NPhv/87TJN2mWOz335VOwlWjTtMnAivvBKu6LfbDr73\nPdi0KUxvbIQf/QiGD4cxY+COO+CLX4T3vz9Mf897wt/VjdF7zOfggw92kYLa2sInia1b3TdudL/w\nQndw/8UvQvq997rvuaf7m2/mXm7LlrBc5pOxeXN72lNPuQ8b5j5pUpj2pz+5v/vd7nffnTuOU08N\nMfz4x2H5rVuTb3N3efPNjttdaPszn02bOufz1lthWvb+bW3t+PeWLe7f+U7YL+94h/vf/lb5bSpF\n5rjHj80bb7Rva0tLe/qbb7rfeWeIffLk3Pm1trpPmRLydXdfvz75b7dEhC77nc6pNT+pl/JRASAF\nrV3r/pGPuB9yiPurrxaet6nJ/b3vDf8FwH3ChPYT0H33hbQrrui83B13uO+0U/tyu+3WPu1zn2tP\nB/eBA90bG5PFvm2b+5lnti/73e8mW67ampraT0qnndZx+8D9Xe9qn/fEEztPHzasffqrr7rfdJN7\n//5h2pe/3D7t4YfdBw1yv+CC9vX98pdhvjPPdD/oIPcdd8x/XL/4RffDD6/aCdRfesl9l13at+mN\nN8LvI76tu+wSLh6amtz79Qtpe+0VCrway1cAqAlIqs89NHMMGwYf/3jl8//HP+CPfwzt6M88A/36\nwYMPwkknwYwZsGQJfPWrsOeesHo1vPe9oZlnwAD4xS9C+vjxoakG4KijwufSS+H550Oz0EknhTb8\nsWND08348WHe/v3b4zjtNBg9Onw3g+OPhxEjkm1D377w29/CkUeG2M4/P6S7t8dVirlzQ9NJts99\nLtyHANiyBXbYofM8CxfC738fmrCmToWrr4avfAXGjYODDuo474AB7d9PPx0+8pGO03eOhv7617/g\niCNg82Y47DA44QQ4MBol/s9/hhNPDM1lV1wBb70Fv/lN2Bd/+ENY77p18OijEB8O5vbboU8f+NSn\n4IEHYMUKuO22sI2Vtssu4Tf02mthf0yZEpp0PvEJOProMM+MGfC3v8Fll8Hvfhd+a0cdlXsf14tc\npUK9flQDqIENG9zXrOn4yVSB33yzvfqaT1ub+w9+EK6Gvva13Hlu29Y+bylNH5kr9qlTw9XXXnu5\n//Wv7s3N7fN8+cvhamzIEPdPfSpcvWWaLeJV9mz//Gdostlll9AMkZn/2GPdX3steYxdsWKF+8EH\nuz/4YO799cYbnY/NmjVhv6xa5f7+94f4459rrgnLXnihe0NDx2aX1lb3k04Kx2q77cL8xx/fsZmn\nXJs3h7xPPDHEHfeDH7h/9KMh5p/+NNTiCh2b22/vWFu6+uqwT/bbz33kyPb9U8zrr4f9VWqt4ROf\nCDWf11/vmL5hQ/VqIF2EmoCkZDfc4N6nT+dqfaZZ45prQhPIRRe5r1vXefm2tlClB/cvfan9ZJNp\n7858DjrI/eWX3ZcvD//5ly4tHtuzz7oPH+7+yCPF521qch88OKzryisTb37NPf+8+/ve13n/P/98\nmH7ppZ2nQTipFTNjRpj3lls6pl9wQTiea9dWfnsqoa3N/ZhjQuxjx4ZC/ZxzwrSbbw7pP/xh8Xwe\nf9zdLMx/5JHh95Qp2F9/PRRY7uEexhlnhEInY+7c0Ny3cmVlt62K8hUAGgqiN5o1C9auhTPOgHe8\no+O0LVvg8stDv+Kf/zxUuyGcOv7v/0Jzye67w89+Fqq7P/lJ52aMU04J8yxcGHoxzJ4N73xn6OUy\nYgT88IdhvrPOguuug298A3796/amjHvugaefDt/ffBMmTYJPfxomT4ZjjglV5+OPb1/f//xPaGq4\n9dZQxQaYNw8WLYJly0JviWKWLw+fo44qaVfW3CuvhGaNeJ/x008PTSuNjTBnTudlzj67Y9NMLq2t\noTln82YYNQq+/e32pqF6t3kz3HVX+I24hya/Pn3C97PPhv33h+98Bx56CG66qfPyF18cmpJmzoQn\nn2zvinnMMfDXv4aeWNOmwWc+A/Pnh8+MGdXvkVNF+YaCqPlVfSkf1QCKWLWq/cYZuL/nPe1XNa+8\n4v7CC6H6Cu677x6uutvaQrU7cwNv0CD30aNLW++CBe6nnBKaTI48sj39k58MvVqKVYvnzm2vQTzx\nhPuBB4b4Mp8NG8K0n/60Y/pll5UWp3R0xx3hRvjuuye7au4J4r+1adM6/l4yn+XLOy5z223uo0a5\n/+Mf4e+HHw7/T3bf3X3o0FCz6OFQDSAF9t039F///OfDDatHH22/Gt9vv3DVbRZuUJ15ZkjfsAE+\n/GF46in4wQ/gkkvKu+koInUrXw1AvYB6ssmToakJzjknnMQnTQrpn/tcqBYfeWT7vD/7Gbz+Ohxw\nQMcHnHbeGR55JPTSOOaY7o1fRGpKNYCeYNOm0JbfJzZyx7/+BQcfDIMGhSv6sWNrF5+I1DUNB91T\nvfgi7LFHuFF3zz3t6T/6EQwcCM89p5O/iJRFBUC1TZ4cHkoq5o03Qrv9qafClVeG27gQmnVaWsJY\nIhs3hrSZM0MviO9/v/1BGxGREukeQDU98wx885thZL9bbw1dHfOZNSs8YThkSLh5+8Uvhq6aU6fC\n178enpDMMAtP1H7ta9XfBhHptRLVAMxsjJk9bWZLzWxijulDzex+M5tvZk+Y2XFR+jFmNs/MFkb/\nHhVb5oEoz6bos3vlNqtOzJoVTtb77x/a7CEM+5q5ko+bORPe977Q5PPPf8K73hVu2g4YEPol9+nT\nfg/glFNCrWLHHbtvW0Sk1ylaAzCzvsAU4BhgBTDXzGa7+5LYbD8Cbnb3q8xsJHAnMAxYA3zG3V82\nswMJL5bfM7bcqe7ee+7q/uUv4YGRvn3DVfusWeHhmjvvbH+jzwUXhIdNMmOq7LxzGCJ2zpxQWzBr\nH+9k//3h4YeTPegkIlKiJE1AhwJL3X0ZgJnNBMYC8QLAgUxj9C7AywDuPj82z2JggJnt4O5buhp4\nt1izJpy4d945jNldyO9/H57QfPe7Q3v9woWhnX79+nClvu++Yb7jjguDlz31VPh7+fIwiNXLL4fl\n4gYODB8RkSpIUgDsCbwU+3sF8OGseS4C7jGzrwM7AkfnyOdzwL+yTv7TzKwVuBW4xHP0STWzCcAE\ngKFDhyYIt0Iyj8ivXBmuyh95pPNIhxnLloVhF444IgyLsHlzuKk7dGj4xH3iE+GT0dgYrvjf+c6q\nbYqISC6V6gU0Hpju7kOA44AbzOztvM3sAOBy4JzYMqe6+0HAx6LPl3Jl7O7XunuDuzcMjg8FW22/\n+U04+V95ZXjIKle7fcY++4QT/x13wE47hXFyitUYMhoaYO+9KxOziEgJktQAVgJ7xf4eEqXFnQWM\nAXD3OWbWHxgEvGpmQ4A/Aae5+3OZBdx9ZfTvRjP7A6Gp6fpyN6Si2trgmmvg2GPDQGbf+EZIX7Kk\n/XVuEMafP/jgMN9xx9UmVhGRMiUpAOYCI8xsOOHEPw74QtY8LwL/CUw3s/2B/sBqM9sVuAOY6O7/\nyMxsZv2AXd19jZltB3wa+FuXt6ZS+vQJPXFee61j+llnhZc8x512WigARER6mKIFgLtvM7PzCT14\n+gLXuftiM7uYMMLcbODbwG/N7ALCDeEz3N2j5f4N+ImZ/STK8ljgDeDu6OTfl3Dy/22lN64sy5aF\ndvvddgufuF/9qmOh8I539JwhdEVEsmgsoLgNG8Lr/j7ykfAqOhGRXkCjgWZbsyaMo/PhD4cndn/8\n4/COz5deCn34RUR6uXSOBbRtW3iR8/HHh+6aixaFoRpuvBEmTgwvrRapoOaNzRwx/QhWbVpVs3Uv\nWLWg7BhyxV9om5Kus3ljM6N/N5rDph6WOL5CsSxYteDt/AqtsxLHIp5PLY9vl+R6S0y9fir2RrDn\nngtvv5o8uT3t//0/93PPLf6Sc5EyfPUvX/U+P+vj5/3lvJqt+4ApB5QdQ674C21T0nV+9S9fdS7C\nuYjE8RWK5YApB7ydX6F1VuJYxPOp5fFNAr0RLKaxEQ45JPTd/8xnup6fSAHNG5vZZ/I+vLXtLQb0\nG8Cyby7jPTt1z/Ae8XVnlBpDrvjdPe82JV1n88Zmhl85nC2tHQcGKBRfsVji+vfrz/JvLu+0zkoc\ni3g+/fv2B+Ct1u4/vknpfQBx69eHf7N7+YhUwaSHJtHmbQC0eiuTHpxUk3VnlBpDrvgLbVPSdU56\naBJbW7OGPykSX7FY4lpaW3KusxLHIp5PS2sLLW0tXc6zFtJZA5g1C8aNg8WLYeTIrucnkkclrsAr\nue5SY8iVR/yKNzu/fFfj2evMd/VfKL6kscTFawGVOhaF9mu5eVabagBxJ5wQhl0eMaLWkUgvV4kr\n8Equu9QYcuURv+LNzi/pOvNd/ReKL2ks2dPj66zEsSi0jeXmWSvpLAB22AH22it0+5SqiffwSNI7\nolf0qsgyZ8UcWlo7nqBaWlt4dMWjVVtnZr/PWDCj07pLjSFX/G205TwRT2uaVnSdMxbMYMGqBVy/\n4HrayH8SzeQX/+0kjaXDdG9jxoIZrNq0iodeeCjnscisJ94LKVevosz3QtuYybPU41uz33uuO8P1\n+qlYL6DZs91/+cvK5CV5xXt4JOkd0ZN6VdSzQvu9nP2afVxy5V2oN092j6BCvX2K9ebJ9RtJkl++\n31S+uHPFkf29kr/Pav/eUS+gmDPPhHvvDQ99SVVkt/Hm6pGRPX9P6lVRrwrt93J6wGQfF3dnS1vH\nvN09b2+eOWfNYfTU0YnuQ+RrW4+vJ9dvJEl+uX5T+eIudl+h0DaUozt6iekeQNy6deoBVGXZbby5\nemRkz98belXUWqH9Xk4PmOzjkjn5x/Mu1Jvn1NtOTXwfolhvnny/kST55fpN5Yu72H2FQussRy17\niaWzBnDEEeElLw880PW8pJN8PTzy1QJ6Yq+KelRovz921mOdrsSL7ddixwVgh747gNOhYChFkt5D\nmfUYVvSqPGl+2bWZrqjU8wSVyC8f1QDiVAOoqkJXVrmubnpTr4paKrTfc12JF9uvxY4LwJbWLV06\niSbpPZRZT5Kr8qT5ZddmuqJSzxNUIr9SpbMAWL9e79qtsHiviRlNM3L28GjzNh584cFO81+/4Pqi\nvSqmL5jeaeyXUseQ6apSemrk69GU63slxugptt+fW/9czh4wmeORS65eN5WW6TGTZF3FCqNS8ivU\nA6lU8V4/pfwumzc25/ztV7uXWAe57gzX66divYBaWtw3bapMXuLupfXeyJ4/uydHV3udVHsbu9Kj\nqdReLEnXk2QMnHK3pdaqEWu1tr+U32V3HgPUC0iqpZTeG8V6hsR7YJTT66Ra9wpK6amRr/dJvu/l\nxl9svyeJr97vr1Qj1mptfyljG3X3MdA9gIx16+BrX4O5c2sdSa9RSu+NYj1D4j0wyul1Uq2201J6\nauTrfZLve0ZXxuiJK6XHVb3fX6lGrNXa/lJ+l/VyDBLVAMxsDHAl4fWNv3P3y7KmDwVmALtG80x0\n9zujaRcSXhrfCnzD3e9OkmcuFakBLF4MBx4YxgM6+eSu5SVFe4ok7b2RVLFeJ9W4miqlp0aSnjOF\ndGWMnrhSelzVay2gGrFWa/tLGduoFseg7BqAmfUFpgCfBEYC480sewS1HwE3u/uHCC+N/0207Mjo\n7wOAMcBvzKxvwjyrY9268K9uAldEpXpvJFWs10k1rqZK6amRpOdMIV0ZoyeulB5X9VoLqEas1dr+\nUsY2qqdjkKQJ6FBgqbsvc/cWYCYwNmseB3aOvu8CvBx9HwvMdPct7r4cWBrllyTP6kgwFHQ543Jk\n3/0v9j1XL5BCy8V7jiRZTzXG1Mm17mLjokCy3huVEh9vJr7dhcZ2KdZjI994PtMXTO+0r2c0Fd8f\nxeKPj4GT7+1XxdbT5m05e5Lk25Zc6+yu3lX5VHIcpcw25RsPqKu9buasmFN0bKP4OEj5emQV+o1W\n4zgUbQIys5OAMe5+dvT3l4APu/v5sXn2AO4BdgN2BI5293lm9n/AY+7++2i+qcBd0WIF84zlPQGY\nADB06NCDX3jhha5sL0yfDl/+MixbBsOH55zlvDvO45p513Duwecy5VNTEmV73h3ncVXjVQAcMPgA\nFq9eXPD7eQ3n4TjXzLuG/Qftz5NrnmT/QfvnXe7JNU9y7sHn4nii9cTnL3VbSt3G8xrOS5R3Ofs1\naR6Z9Pi+zOyDKZ+a0mF6sX2WK7b4erOPQa5jEz++SbY3V3z58ogfh6T7vpx1Zu/DnqwSv72urLfY\n7zL+fzXfb7QrxzpfE1ClCoD/ivL6lZkdBkwFDgQm08UCIK4i9wCuuiq89H3NGth1106Tyx0vpVD7\nXy7ltI2X+vRiJcfUKbSNxXqdZJbvaq+HfHkUG/e+UK+jXPMX6rGR7xhkp8ePb7lP3ObKI7sHVJJ9\nX+46C+2TnqRWvZ5K+V0mGX+o3GMNXesFtBLYK/b3kCgt7izgZgB3nwP0BwYVWDZJntXx1a/C1q2w\nyy45J5c7Xkqh9r9cymkbL/XpxUqOqVNoG4v1Osks39VeD/nyKDYGfaFeR7nmL9RjI98xyE6PH99y\nn7jNlUepYyx1ZZ0Z9XqPIKla9bgp5XeZZPyhco91IUlqAP2AZ4D/JJyk5wJfcPfFsXnuAma5+3Qz\n2x+4D9iTcIP3D4Q2//dG6SMAK5ZnLtV+DqCcu/PlXP3XSleuvIttY6Grk0q/lzaeRylX90klrV2U\nm2dcKfnnrX2UeGVYzjb11FpArXo9Vep3k63cWkDZNQB33wacD9wNPEno7bPYzC42s+Oj2b4NfMXM\nFgA3AWdED6AtJtQMlgB/Bb7m7q358ixpi8r185/DRRflnFTO3flyrv5rpStX3sW2sdDVSaXfSxvP\no5Sr+6SS1i7KzTOulPwL1T4q8fxAIT21FlCrHjeV+t1kq3QtoF+SmaI+/Xdmpf0k9n0JcHieZS8F\nLk2SZ7e4/XbYaaeck/L1Oig2XkolxxWppkzPlQkHT+Ccv5yDmXH1p67u8P0bf/0Gs06ahbtz4qwT\nMTPWv7m+6Dbm63UClenNkS+PXGPcdFW8R8Yrm16pSP75treU8XbyHYNC+z6Xcsb46dbxaSqoFm9k\ny7feSij1WBeVa3yIev1UZCyg977X/Ywzis/nPWu8lGKyxygp9pajWoy1Uy1deQtWLbc93/hJPfU4\nSO2gsYCAlhbo3x9+/GP42c8KztqTxkspptT7FPnamnvifujqW7Ayunvbs+OO3+voicdBaktjAQG8\n/DK4hxfCF1EvY3VUQqn3KfK1NffE/dDVt2BldPe2Fxo/qSceB6lP6SoAXn8d9t4bhg0rOFvzxmam\nNU17uw0v86RkrZ6I7Irmjc1cN/+6ku5T5Ju3p+2Hco5j9jIZ3bntueJevHpxr/g9Sn1JVwHwwQ/C\n88/D0UcXnC3XFeDW1q188KoPdusLSCqh0r2UetLVZ7m9upK+w7ZakvQg6UnHQepXugqAhHLdwd/m\n23h186s8tuIxTr3tVB558ZEe8R+w0r2UelJvkHJ6gBTqvdFd256kB0lPOg5Sv9J1E/jnP4dFi+DG\nGxPNrpeVp09vuvkvkqGbwACPPhreB5CQXlaePr3p5r9IMekqAF56CYYOTTRrvpuBcboZ17v0ppv/\nIkmkqwB48cVEXUAh+aPcukrsPeqh+6dId0pPAfDGG+FlMHkKgOwXbyR9lLvYUBHSc9Rq2ACRWkk0\nFlCvsH49HHYYfOADOSdPemjS2z17pnxqCvPPmV80y8zLHI7Y+4hKRys1kOSYi/Qm6eoFlEdXhwtQ\nbxERqWfqBVRAV4cLUDuxiPRE6SkAFi2CAw+Ehx7qkFyJ4QLUW0REeqL0FACbNoVnAN54o0NypYYL\nUC1ARHqa9BQAra3h3759OyRXargA9RYRkZ4mPb2A8hQA5fT8UG8REekNEtUAzGyMmT1tZkvNbGKO\n6VeYWVP0ecbMXovSj4ylN5nZW2Z2QjRtupktj00bVdlNy9IWNdlkFQAiImlVtAZgZn2BKcAxwApg\nrpnN9vAeYADc/YLY/F8HPhSl3w+MitIHAkuBe2LZf9fdb6nAdhS3665w7LEwcGC3rE5EpN4laQI6\nFFjq7ssAzGwmMBZYkmf+8cBPc6SfBNzl7pvLCbTLRo2Cu++uyapFROpRkiagPYGXYn+viNI6MbO9\ngeHA33NMHgfclJV2qZk9ETUh7ZAnzwlm1mhmjatXr04QroiIJFHpXkDjgFvcvTWeaGZ7AAcB8Uvw\nC4H9gEOAgcD3c2Xo7te6e4O7NwwePLj8yO67L7wO8okngNCXf/TvRve4N3yJiFRKkgJgJRAfQW1I\nlJZLrqt8gJOBP7n72+8mdPdmD7YA0whNTdWzaVMYDXTbNiD05X985eM97g1fIiKVkqQAmAuMMLPh\nZrY94SQ/O3smM9sP2A2YkyOP8WQVDFGtADMz4ARgUWmhlyjWDTTzovSMxasX0+ZteppXRFKlaAHg\n7tuA8wnNN08CN7v7YjO72MyOj806DpjpWaPLmdkwQg0ie8zkG81sIbAQGARcUu5GJBIrAPK9KF1P\n84pImqRnNNCZM2H8eJrnPcjwO49lS+uWnLNpZE8R6W00GuiQIfDZzzLp2d/lvPrPUC1ARNIiPQXA\nRz8Kt97KnNcW0kb+Vz1qTB8RSYv0jAUU0Tg+IiJBemoAv/89vOtdsGJFrSMREakL6SkANm+GdevA\nrNaRiIjUhfQUAHmGgxYRSSsVACIiKaUCQEQkpdJTAOy/P5x+OvTvX+tIRETqQnq6gR57bPiIiAiQ\nphqAiIh0kJ4C4LLLYPvtYUvuMYBERNImPQXA1q3ho5vAIiJAmgqAqBdQ8+ZX9fYvERHSVgCYMenh\nS/T2LxERUlYANO/Sh2lN0/T2LxER0lQAjB7NpHNH0uZhKGiN+y8iaZeoADCzMWb2tJktNbOJOaZf\nYWZN0ecZM3stNq01Nm12LH24mT0e5Tkret9w1TQfeQjTdnqWltYWIIz7r1qAiKRZ0QLAzPoCU4BP\nAiOB8WY2Mj6Pu1/g7qPcfRTwv8BtsclvZqa5e/wdwpcDV7j7vwHrgbO6uC0FTXrgZ29f/WeoFiAi\naZakBnAosNTdl7l7CzATGFtg/vHATYUyNDMDjgJuiZJmACckiKVsc/5569tX/xl6+5eIpFmSoSD2\nBF6K/b0C+HCuGc1sb2A48PdYcn8zawS2AZe5+5+BdwGvufu2WJ575slzAjABYOjQoQnCzW3++lPg\npptg7dqy8xAR6U0qPRbQOOAWd2+Npe3t7ivNbB/g72a2EHg9aYbufi1wLUBDQ4OXHVlrqx4CExGJ\nSdIEtBLYK/b3kCgtl3FkNf+4+8ro32XAA8CHgLXArmaWKYAK5VkZKgBERDpIUgDMBUZEvXa2J5zk\nZ2fPZGb7AbsBc2Jpu5nZDtH3QcDhwBJ3d+B+4KRo1tOB27uyIUWpABAR6aBoE5C7bzOz84G7gb7A\nde6+2MwuBhrdPVMYjANmRif3jP2Ba8ysjVDYXObuS6Jp3wdmmtklwHxgamU2KY/jjoN9963qKkRE\nehLreL6ubw0NDd7Y2FjrMEREehQzm+fuDdnp6XkSeMMGWL++1lGIiNSN9BQAX/kKHHZYraMQEakb\n6SkAdBNYRKQDFQAiIimlAkBEJKVUAIiIpFSlh4KoX6efDps31zoKEZG6kZ4C4OSTax2BiEhdSU8T\n0MsvQ3NzraMQEakb6akBfOEL4d8HHqhpGCIi9SI9NQDdBBYR6UAFgIhISqWrAOiTns0VESkmPWdE\n1QBERDpIz03g730PBgyodRQiInUjPQWAngMQEekgPU1ATz1F81NzOWL6EazatKrW0YiI1FyiAsDM\nxpjZ02a21Mwm5ph+hZk1RVCiMvIAAA7mSURBVJ9nzOy1KH2Umc0xs8Vm9oSZnRJbZrqZLY8tN6py\nm5XDCScw6arxPPLiI0x6cFJVVyUi0hMULQDMrC8wBfgkMBIYb2Yj4/O4+wXuPsrdRwH/C9wWTdoM\nnObuBwBjgF+b2a6xRb+bWc7dmyqwPXk1b7+Fabs+T5u3Ma1pmmoBIpJ6SWoAhwJL3X2Zu7cAM4Gx\nBeYfD9wE4O7PuPuz0feXgVeBwV0LuTyTDlhLG+H9x63eqlqAiKRekgJgT+Cl2N8rorROzGxvYDjw\n9xzTDgW2B56LJV8aNQ1dYWY7JI66RM0bm5n2bxtp6dMGQEtri2oBIpJ6lb4JPA64xd1b44lmtgdw\nA/Bld2+Lki8E9gMOAQYC38+VoZlNMLNGM2tcvXp1WUFNemgSbVlpqgWISNolKQBWAnvF/h4SpeUy\njqj5J8PMdgbuAH7o7o9l0t292YMtwDRCU1Mn7n6tuze4e8PgweW1Hs1ZMYeWrA6vLa0tPLri0bLy\nExHpDZI8BzAXGGFmwwkn/nHAF7JnMrP9gN2AObG07YE/Ade7+y1Z8+/h7s1mZsAJwKKyt6KI+efM\nr1bWIiI9VtEagLtvA84H7gaeBG5298VmdrGZHR+bdRww0909lnYy8HHgjBzdPW80s4XAQmAQcEkF\ntie/xx+H5curugoRkZ7EOp6v61tDQ4M3NjaWt/Buu8GXvgSTJ1c2KBGROmdm89y9ITs9PU8CazA4\nEZEOVACIiKSUCgARkZRSASAiklLpGQ76j3+EESNqHYWISN1ITwFwwgm1jkBEpK6kowmorQ3uugue\ne674vCIiKZGOAmDbNjjuOJg5s9aRiIjUjXQUAK3R2HS6CSwi8jYVACIiKaUCQEQkpVQAiIikVDq6\ngb7znXDvvbDvvrWORESkbqSjANhuOzj66FpHISJSV9LRBLR5M9x8s94HICISk44CYO1aOOUUuO++\nWkciIlI30lEA6CawiEgnKgBERFIqUQFgZmPM7GkzW2pmE3NMvyL2zt9nzOy12LTTzezZ6HN6LP1g\nM1sY5Tk5ejl8dagAEBHppGgvIDPrC0wBjgFWAHPNbLa7L8nM4+4XxOb/OvCh6PtA4KdAA+DAvGjZ\n9cBVwFeAx4E7gTHAXRXaro5UAIiIdJKkBnAosNTdl7l7CzATGFtg/vHATdH3TwD3uvu66KR/LzDG\nzPYAdnb3xzy8lf56oHrjNQ8bBnPmqCuoiEhMkgJgT+Cl2N8rorROzGxvYDjw9yLL7hl9T5LnBDNr\nNLPG1atXJwg3hwEDYPRoGDSovOVFRHqhSt8EHgfc4u6tlcrQ3a919wZ3bxg8eHB5maxZA1Onwosv\nViosEZEeL0kBsBLYK/b3kCgtl3G0N/8UWnZl9D1Jnl23fDmcfTY88UTVViEi0tMkKQDmAiPMbLiZ\nbU84yc/OnsnM9gN2A+bEku8GjjWz3cxsN+BY4G53bwY2mNnoqPfPacDtXdyW/Nrawr990tHrVUQk\niaK9gNx9m5mdTziZ9wWuc/fFZnYx0OjumcJgHDAzuqmbWXadmU0iFCIAF7v7uuj7ecB0YACh9091\negCBegGJiOSQaDA4d7+T0FUznvaTrL8vyrPsdcB1OdIbgQOTBtolKgBERDpJR5uICgARkU7SMRz0\nIYfAokXheQAREQHSUgDsuCMccECtoxARqSvpaAJavhyuvBJWrap1JCIidSMdBcDixfCtb8FLLxWf\nV0QkJdJRAOgmsIhIJ+koAPQgmIhIJ+k4I6oGICLSiQoAEZGUSkc30M98Bl54AfbYo9aRiIjUjXQU\nAO94BwwdWusoRETqSjqagJqa4JJL4LXXis8rIpIS6SgA5s2DH/8YNmyodSQiInUjHQWAbgKLiHSi\nAkBEJKVUAIiIpJQKABGRlEpUAJjZGDN72syWmtnEPPOcbGZLzGyxmf0hSjvSzJpin7fM7IRo2nQz\nWx6bNqpym5Xl3HNh7VrYddeqrUJEpKcp+hyAmfUFpgDHACuAuWY2292XxOYZAVwIHO7u681sdwB3\nvx8YFc0zEFgK3BPL/rvufkulNiavHXYIHxEReVuSGsChwFJ3X+buLcBMYGzWPF8Bprj7egB3fzVH\nPicBd7n75q4EXJb774eJE2Hr1m5ftYhIvUpSAOwJxAfSXxGlxe0L7Gtm/zCzx8xsTI58xgE3ZaVd\namZPmNkVZla9S/RHH4XLLwf3qq1CRKSnqdRN4H7ACOA/gPHAb83s7QZ3M9sDOAi4O7bMhcB+wCHA\nQOD7uTI2swlm1mhmjatXry4vOt0EFhHpJEkBsBLYK/b3kCgtbgUw2923uvty4BlCgZBxMvAnd3+7\nDcbdmz3YAkwjNDV14u7XunuDuzcMHjw4Qbg5ZAoAvQ9ARORtSc6Ic4ERZjbczLYnNOXMzprnz4Sr\nf8xsEKFJaFls+niymn+iWgFmZsAJwKIy4k+mtTWc/M2qtgoRkZ6maC8gd99mZucTmm/6Ate5+2Iz\nuxhodPfZ0bRjzWwJ0Ero3bMWwMyGEWoQD2ZlfaOZDQYMaALOrcwm5dDWpuYfEZEs5j3oxmhDQ4M3\nNjaWvmBbW6gFbLdd5YMSEalzZjbP3Ruy09PxPoA+fdT+LyKSJR1nxT/+Eb7znVpHISJSV9JRADz8\nMEydWusoRETqSjoKgNZW3QQWEcmiAkBEJKVUAIiIpFQ6CoB+/WDAgFpHISJSV9LRDfSqq2odgYhI\n3UlFDaB5YzNHTD+CVZtW1ToUEZG6kYoCYNKUk3nk+YeY9OCkWociIlI3en0B0LyxmWlvPkqbwbSm\naaoFiIhEen0BMOmhSbRF31u9VbUAEZFIry4Amjc2M61pGi19QhHQ0tqiWoCISKRXFwCTHppEm7d1\nSFMtQEQk6NUFwJwVc2hpbemQ1tLawqMrHq1RRCIi9aNXPwcw/5z5tQ5BRKRu9eoagIiI5KcCQEQk\npRIVAGY2xsyeNrOlZjYxzzwnm9kSM1tsZn+IpbeaWVP0mR1LH25mj0d5zopeOC8iIt2kaAFgZn2B\nKcAngZHAeDMbmTXPCOBC4HB3PwD4Vmzym+4+KvocH0u/HLjC3f8NWA+c1bVNERGRUiSpARwKLHX3\nZe7eAswExmbN8xVgiruvB3D3VwtlaGYGHAXcEiXNAE4oJXAREemaJAXAnsBLsb9XRGlx+wL7mtk/\nzOwxMxsTm9bfzBqj9MxJ/l3Aa+6+rUCeAJjZhGj5xtWrVycIV0REkqhUN9B+wAjgP4AhwENmdpC7\nvwbs7e4rzWwf4O9mthB4PWnG7n4tcC1AQ0ODVyheEZHUS1IDWAnsFft7SJQWtwKY7e5b3X058Ayh\nQMDdV0b/LgMeAD4ErAV2NbN+BfIUEZEqSlIAzAVGRL12tgfGAbOz5vkz4eofMxtEaBJaZma7mdkO\nsfTDgSXu7sD9wEnR8qcDt3dxW0REpAQWzsVFZjI7Dvg10Be4zt0vNbOLgUZ3nx3d1P0VMAZoBS51\n95lm9hHgGqCNUNj82t2nRnnuQ7ihPBCYD3zR3bcUiWM18EIZ2zkIWFPGctWmuEpXr7HVa1xQv7HV\na1xQv7GVG9fe7j44OzFRAdDTmVmjuzfUOo5siqt09RpbvcYF9RtbvcYF9RtbpePSk8AiIimlAkBE\nJKXSUgBcW+sA8lBcpavX2Oo1Lqjf2Oo1Lqjf2CoaVyruAYiISGdpqQGIiEiWXl0AJBnFtJvi2MvM\n7o+NlvrNKP0iM1sZGy31uBrF97yZLYxiaIzSBprZvWb2bPTvbt0c0/tj+6XJzDaY2bdqtc/M7Doz\ne9XMFsXScu4jCyZHv7snzOzfuzmuX5rZU9G6/2Rmu0bpw8zszdi+u7pacRWILe/xM7MLo332tJl9\nopvjmhWL6Xkza4rSu22fFThPVO935u698kN4ZuE5YB9ge2ABMLJGsewB/Hv0/Z2EJ6VHAhcB36mD\nffU8MCgr7RfAxOj7RODyGh/LVcDetdpnwMeBfwcWFdtHwHHAXYABo4HHuzmuY4F+0ffLY3ENi89X\no32W8/hF/x8WADsAw6P/u327K66s6b8CftLd+6zAeaJqv7PeXANIMoppt3D3Znf/V/R9I/AkeQa/\nqyNjCaO0Qu1Ha/1P4Dl3L+chwIpw94eAdVnJ+fbRWOB6Dx4jDHuyR3fF5e73ePtAi48Rhlrpdnn2\nWT5jgZnuvsXDcDJLCf+HuzWu6KHWk4GbqrHuQgqcJ6r2O+vNBUCSUUy7nZkNI4yH9HiUdH5Ufbuu\nu5tZYhy4x8zmmdmEKO3d7t4cfV8FvLs2oQFh+JH4f8h62GeQfx/V02/vTMJVYsZwM5tvZg+a2cdq\nFFOu41cv++xjwCvu/mwsrdv3WdZ5omq/s95cANQdM9sJuBX4lrtvAK4C3geMApoJVc9a+Ki7/zvh\npT9fM7OPxyd6qG/WpLuYhfGnjgf+GCXVyz7roJb7KB8z+yGwDbgxSmoGhrr7h4D/Av5gZjt3c1h1\nefxixtPxYqPb91mO88TbKv07680FQJJRTLuNmW1HOKg3uvttAO7+iru3unsb8FuqVOUtxttHbH0V\n+FMUxyuZ6mT0b8GX/FTRJ4F/ufsrUYx1sc8i+fZRzX97ZnYG8Gng1OikQdS8sjb6Po/Qzr5vd8ZV\n4PjVwz7rB3wWmJVJ6+59lus8QRV/Z725AEgyimm3iNoVpwJPuvv/xNLj7XUnAouyl+2G2HY0s3dm\nvhNuIC4i7KvTo9lqOVprhyuyethnMfn20WzgtKiXxmjg9VgVvuosvJDpe8Dx7r45lj7YwiteM4Mx\njgCWdVdc0XrzHb/ZwDgz28HMhkex/bM7YwOOBp5y9xWZhO7cZ/nOE1Tzd9Ydd7dr9SHcJX+GUGr/\nsIZxfJRQbXsCaIo+xwE3AAuj9NnAHjWIbR9C74sFwOLMfiK8te0+4Fngb8DAGsS2I+HdEbvE0mqy\nzwiFUDOwldDWela+fUTolTEl+t0tBBq6Oa6lhLbhzG/t6mjez0XHuAn4F/CZGuyzvMcP+GG0z54G\nPtmdcUXp04Fzs+bttn1W4DxRtd+ZngQWEUmp3twEJCIiBagAEBFJKRUAIiIppQJARCSlVACIiKSU\nCgARkZRSASAiklIqAEREUur/AzIayx8k2JssAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbyuA8m_FhiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "325dff19-054b-42ae-cbe7-bb88d0fb6e3a"
      },
      "source": [
        "model=build_neural_network()\n",
        "restorer=tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "  restorer.restore(sess,\"./titanic.ckpt\")\n",
        "  feed={\n",
        "      model.inputs:test_data,\n",
        "      model.is_training:False\n",
        "  }\n",
        "  test_predict=sess.run(model.predicted,feed_dict=feed)\n",
        "\n",
        "test_predict[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./titanic.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11659506],\n",
              "       [0.40112156],\n",
              "       [0.02048436],\n",
              "       [0.14087674],\n",
              "       [0.3593511 ],\n",
              "       [0.13242844],\n",
              "       [0.6147425 ],\n",
              "       [0.15695527],\n",
              "       [0.6183718 ],\n",
              "       [0.17176211]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl15aQN-Fj69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e3eed80b-c1b9-412e-dd2c-67c15084a471"
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "binarizer=Binarizer(0.5)\n",
        "test_predict_result=binarizer.fit_transform(test_predict)\n",
        "test_predict_result=test_predict_result.astype(np.int32)\n",
        "test_predict_result[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAd8FzPQFl6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "ff89bd89-d52f-4299-99a8-d2df1312427d"
      },
      "source": [
        "passenger_id=test_passenger_id.copy()\n",
        "evaluation=passenger_id.to_frame()\n",
        "evaluation[\"Survived\"]=test_predict_result\n",
        "evaluation[:10]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>897</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>898</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>899</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>900</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>901</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         0\n",
              "2          894         0\n",
              "3          895         0\n",
              "4          896         0\n",
              "5          897         0\n",
              "6          898         1\n",
              "7          899         0\n",
              "8          900         1\n",
              "9          901         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcAYsSqrFoRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation.to_csv(\"evaluation_submission.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}